# Comparing activation function ReLU vs Mish

*  Mish is Self Regularized Non-Monotonic Activation Function
*  ReLU ( Rectified Linear Unit )

